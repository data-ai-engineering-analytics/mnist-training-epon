{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0m2JWFliFfKT"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import base64\n",
        "from io import BytesIO\n",
        "from tabnanny import verbose\n",
        "\n",
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TrainingReportGenerator:\n",
        "    def __init__(self, reports_dir=\"reports\"):\n",
        "        self.reports_dir = reports_dir\n",
        "        self._ensure_reports_directory()\n",
        "        self.report_data = {\n",
        "            'experiment_info': {},\n",
        "            'model_info': {},\n",
        "            'training_history': [],\n",
        "            'test_results': {},\n",
        "            'plots': [],\n",
        "            'metadata': {}\n",
        "        }\n",
        "    \n",
        "    def _ensure_reports_directory(self):\n",
        "        \"\"\"Create reports directory if it doesn't exist\"\"\"\n",
        "        if not os.path.exists(self.reports_dir):\n",
        "            os.makedirs(self.reports_dir)\n",
        "            print(f\"Created reports directory: {self.reports_dir}\")\n",
        "    \n",
        "    def log_experiment_info(self, model_name, dataset, batch_size, epochs, optimizer, scheduler=None):\n",
        "        \"\"\"Log basic experiment information\"\"\"\n",
        "        self.report_data['experiment_info'] = {\n",
        "            'model_name': model_name,\n",
        "            'dataset': dataset,\n",
        "            'batch_size': batch_size,\n",
        "            'epochs': epochs,\n",
        "            'optimizer': str(optimizer),\n",
        "            'scheduler': str(scheduler) if scheduler else None,\n",
        "            'timestamp': datetime.now().isoformat(),\n",
        "            'device': str(device) if 'device' in globals() else 'unknown'\n",
        "        }\n",
        "    \n",
        "    def log_model_info(self, model):\n",
        "        \"\"\"Log model architecture information\"\"\"\n",
        "        total_params = sum(p.numel() for p in model.parameters())\n",
        "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "        \n",
        "        self.report_data['model_info'] = {\n",
        "            'total_parameters': total_params,\n",
        "            'trainable_parameters': trainable_params,\n",
        "            'model_architecture': str(model)\n",
        "        }\n",
        "    \n",
        "    def log_epoch_results(self, epoch, train_loss, train_acc, test_loss, test_acc, lr=None):\n",
        "        \"\"\"Log results for each epoch - handles both single values and lists\"\"\"\n",
        "        # Helper function to extract single value from list or return the value\n",
        "        def extract_value(value):\n",
        "            if isinstance(value, list):\n",
        "                return value[-1] if value else 0\n",
        "            return value\n",
        "        \n",
        "        epoch_data = {\n",
        "            'epoch': epoch,\n",
        "            'train_loss': extract_value(train_loss),\n",
        "            'train_accuracy': extract_value(train_acc),\n",
        "            'test_loss': extract_value(test_loss),\n",
        "            'test_accuracy': extract_value(test_acc),\n",
        "            'learning_rate': lr\n",
        "        }\n",
        "        self.report_data['training_history'].append(epoch_data)\n",
        "    \n",
        "    def log_final_test_results(self, final_test_loss, final_test_acc, incorrect_predictions=None):\n",
        "        \"\"\"Log final test results - handles both single values and lists\"\"\"\n",
        "        # Handle case where final_test_acc is a list (take the last value)\n",
        "        if isinstance(final_test_acc, list):\n",
        "            final_test_acc_value = final_test_acc[-1] if final_test_acc else 0\n",
        "        else:\n",
        "            final_test_acc_value = final_test_acc\n",
        "        \n",
        "        # Handle case where final_test_loss is a list (take the last value)\n",
        "        if isinstance(final_test_loss, list):\n",
        "            final_test_loss_value = final_test_loss[-1] if final_test_loss else 0\n",
        "        else:\n",
        "            final_test_loss_value = final_test_loss\n",
        "        \n",
        "        self.report_data['test_results'] = {\n",
        "            'final_test_loss': float(final_test_loss_value),\n",
        "            'final_test_accuracy': float(final_test_acc_value),\n",
        "            'incorrect_predictions_count': len(incorrect_predictions) if incorrect_predictions else 0\n",
        "        }\n",
        "    \n",
        "    def add_plot(self, plot_type, title, description=\"\"):\n",
        "        \"\"\"Add a plot to the report\"\"\"\n",
        "        # Capture current matplotlib figure\n",
        "        fig = plt.gcf()\n",
        "        buffer = BytesIO()\n",
        "        fig.savefig(buffer, format='png', dpi=150, bbox_inches='tight')\n",
        "        buffer.seek(0)\n",
        "        plot_data = base64.b64encode(buffer.getvalue()).decode()\n",
        "        plt.close(fig)\n",
        "        \n",
        "        self.report_data['plots'].append({\n",
        "            'type': plot_type,\n",
        "            'title': title,\n",
        "            'description': description,\n",
        "            'data': plot_data\n",
        "        })\n",
        "    \n",
        "    def generate_html_report(self, filename=None, custom_name=None):\n",
        "        \"\"\"Generate HTML report in the reports directory\"\"\"\n",
        "        if filename is None:\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            model_name = self.report_data['experiment_info'].get('model_name', 'model')\n",
        "            dataset = self.report_data['experiment_info'].get('dataset', 'dataset')\n",
        "            \n",
        "            if custom_name:\n",
        "                filename = f\"{custom_name}_{timestamp}.html\"\n",
        "            else:\n",
        "                filename = f\"{model_name}_{dataset}_{timestamp}.html\"\n",
        "        \n",
        "        # Ensure filename has .html extension\n",
        "        if not filename.endswith('.html'):\n",
        "            filename += '.html'\n",
        "        \n",
        "        # Create full path in reports directory\n",
        "        filepath = os.path.join(self.reports_dir, filename)\n",
        "        \n",
        "        html_content = self._create_html_template()\n",
        "        \n",
        "        with open(filepath, 'w') as f:\n",
        "            f.write(html_content)\n",
        "        \n",
        "        print(f\"HTML report generated: {filepath}\")\n",
        "        return filepath\n",
        "    \n",
        "    def _create_html_template(self):\n",
        "        \"\"\"Create HTML template with embedded data\"\"\"\n",
        "        exp_info = self.report_data['experiment_info']\n",
        "        model_info = self.report_data['model_info']\n",
        "        training_history = self.report_data['training_history']\n",
        "        test_results = self.report_data['test_results']\n",
        "        plots = self.report_data['plots']\n",
        "        \n",
        "        # Safe formatting with fallbacks\n",
        "        final_acc = test_results.get('final_test_accuracy', 0)\n",
        "        final_loss = test_results.get('final_test_loss', 0)\n",
        "        total_epochs = len(training_history)\n",
        "        total_params = model_info.get('total_parameters', 0)\n",
        "        \n",
        "        html = f\"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>Training Report - {exp_info.get('model_name', 'Unknown Model')}</title>\n",
        "    <style>\n",
        "        body {{ font-family: Arial, sans-serif; margin: 40px; background-color: #f5f5f5; }}\n",
        "        .container {{ max-width: 1200px; margin: 0 auto; background-color: white; padding: 30px; border-radius: 10px; box-shadow: 0 0 20px rgba(0,0,0,0.1); }}\n",
        "        h1 {{ color: #2c3e50; border-bottom: 3px solid #3498db; padding-bottom: 10px; }}\n",
        "        h2 {{ color: #34495e; margin-top: 30px; }}\n",
        "        .info-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; margin: 20px 0; }}\n",
        "        .info-card {{ background-color: #ecf0f1; padding: 20px; border-radius: 8px; border-left: 4px solid #3498db; }}\n",
        "        .metric {{ display: flex; justify-content: space-between; margin: 10px 0; padding: 8px; background-color: #fff; border-radius: 4px; }}\n",
        "        .metric-value {{ font-weight: bold; color: #27ae60; }}\n",
        "        table {{ width: 100%; border-collapse: collapse; margin: 20px 0; }}\n",
        "        th, td {{ padding: 12px; text-align: left; border-bottom: 1px solid #ddd; }}\n",
        "        th {{ background-color: #3498db; color: white; }}\n",
        "        tr:nth-child(even) {{ background-color: #f2f2f2; }}\n",
        "        .plot-container {{ text-align: center; margin: 30px 0; }}\n",
        "        .plot-container img {{ max-width: 100%; height: auto; border: 1px solid #ddd; border-radius: 8px; }}\n",
        "        .summary-stats {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px; margin: 20px 0; }}\n",
        "        .stat-card {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 10px; text-align: center; }}\n",
        "        .stat-value {{ font-size: 2em; font-weight: bold; margin: 10px 0; }}\n",
        "        .timestamp {{ color: #7f8c8d; font-size: 0.9em; }}\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <div class=\"container\">\n",
        "        <h1>üß† Training Report</h1>\n",
        "        <p class=\"timestamp\">Generated on: {exp_info.get('timestamp', 'Unknown')}</p>\n",
        "        \n",
        "        <h2> Experiment Summary</h2>\n",
        "        <div class=\"summary-stats\">\n",
        "            <div class=\"stat-card\">\n",
        "                <div>Final Accuracy</div>\n",
        "                <div class=\"stat-value\">{final_acc:.2f}%</div>\n",
        "            </div>\n",
        "            <div class=\"stat-card\">\n",
        "                <div>Final Loss</div>\n",
        "                <div class=\"stat-value\">{final_loss:.4f}</div>\n",
        "            </div>\n",
        "            <div class=\"stat-card\">\n",
        "                <div>Total Epochs</div>\n",
        "                <div class=\"stat-value\">{total_epochs}</div>\n",
        "            </div>\n",
        "            <div class=\"stat-card\">\n",
        "                <div>Model Parameters</div>\n",
        "                <div class=\"stat-value\">{total_params:,}</div>\n",
        "            </div>\n",
        "        </div>\n",
        "        \n",
        "        <h2>üîß Experiment Configuration</h2>\n",
        "        <div class=\"info-grid\">\n",
        "            <div class=\"info-card\">\n",
        "                <h3>Model & Dataset</h3>\n",
        "                <div class=\"metric\"><span>Model:</span><span class=\"metric-value\">{exp_info.get('model_name', 'Unknown')}</span></div>\n",
        "                <div class=\"metric\"><span>Dataset:</span><span class=\"metric-value\">{exp_info.get('dataset', 'Unknown')}</span></div>\n",
        "                <div class=\"metric\"><span>Device:</span><span class=\"metric-value\">{exp_info.get('device', 'Unknown')}</span></div>\n",
        "            </div>\n",
        "            <div class=\"info-card\">\n",
        "                <h3>Training Parameters</h3>\n",
        "                <div class=\"metric\"><span>Batch Size:</span><span class=\"metric-value\">{exp_info.get('batch_size', 'Unknown')}</span></div>\n",
        "                <div class=\"metric\"><span>Epochs:</span><span class=\"metric-value\">{exp_info.get('epochs', 'Unknown')}</span></div>\n",
        "                <div class=\"metric\"><span>Trainable Params:</span><span class=\"metric-value\">{model_info.get('trainable_parameters', 0):,}</span></div>\n",
        "            </div>\n",
        "        </div>\n",
        "        \n",
        "        <h2>üìà Training History</h2>\n",
        "        <table>\n",
        "            <thead>\n",
        "                <tr>\n",
        "                    <th>Epoch</th>\n",
        "                    <th>Train Loss</th>\n",
        "                    <th>Train Acc (%)</th>\n",
        "                    <th>Test Loss</th>\n",
        "                    <th>Test Acc (%)</th>\n",
        "                    <th>Learning Rate</th>\n",
        "                </tr>\n",
        "            </thead>\n",
        "            <tbody>\n",
        "\"\"\"\n",
        "        \n",
        "        # Add training history rows with safe formatting\n",
        "        for epoch_data in training_history:\n",
        "            train_loss = epoch_data.get('train_loss', 0)\n",
        "            train_acc = epoch_data.get('train_accuracy', 0)\n",
        "            test_loss = epoch_data.get('test_loss', 0)\n",
        "            test_acc = epoch_data.get('test_accuracy', 0)\n",
        "            lr = epoch_data.get('learning_rate', 'N/A')\n",
        "            \n",
        "            # Safe formatting function\n",
        "            def safe_format(value, format_str):\n",
        "                try:\n",
        "                    if isinstance(value, (int, float)):\n",
        "                        return format_str.format(value)\n",
        "                    else:\n",
        "                        return str(value)\n",
        "                except:\n",
        "                    return str(value)\n",
        "            \n",
        "            html += f\"\"\"\n",
        "                <tr>\n",
        "                    <td>{epoch_data.get('epoch', 'N/A')}</td>\n",
        "                    <td>{safe_format(train_loss, '{:.4f}')}</td>\n",
        "                    <td>{safe_format(train_acc, '{:.2f}')}</td>\n",
        "                    <td>{safe_format(test_loss, '{:.4f}')}</td>\n",
        "                    <td>{safe_format(test_acc, '{:.2f}')}</td>\n",
        "                    <td>{lr}</td>\n",
        "                </tr>\n",
        "\"\"\"\n",
        "        \n",
        "        html += \"\"\"\n",
        "            </tbody>\n",
        "        </table>\n",
        "        \n",
        "        <h2> Training Plots</h2>\n",
        "\"\"\"\n",
        "        \n",
        "        # Add plots\n",
        "        for plot in plots:\n",
        "            html += f\"\"\"\n",
        "        <div class=\"plot-container\">\n",
        "            <h3>{plot.get('title', 'Plot')}</h3>\n",
        "            <p>{plot.get('description', '')}</p>\n",
        "            <img src=\"data:image/png;base64,{plot.get('data', '')}\" alt=\"{plot.get('title', 'Plot')}\">\n",
        "        </div>\n",
        "\"\"\"\n",
        "        \n",
        "        html += \"\"\"\n",
        "    </div>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "        return html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "report_gen = TrainingReportGenerator(reports_dir=\"reports\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "h_Cx9q2QFgM7"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1) #input -? OUtput? RF\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.conv5 = nn.Conv2d(256, 512, 3)\n",
        "        self.conv6 = nn.Conv2d(512, 1024, 3)\n",
        "        self.conv7 = nn.Conv2d(1024, 10, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x)))))\n",
        "        x = self.pool2(F.relu(self.conv4(F.relu(self.conv3(x)))))\n",
        "        x = F.relu(self.conv6(F.relu(self.conv5(x))))\n",
        "        x = F.relu(self.conv7(x))\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdydjYTZFyi3",
        "outputId": "b6c9bcac-6a1f-4657-d03c-dab9ea58b696"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /Users/pankajkumar/miniconda3/lib/python3.12/site-packages (1.5.1)\n",
            "MPS Available: True\n",
            "MPS Built: True\n",
            "Using MPS (Apple Silicon GPU)\n",
            "Selected device: mps\n",
            "‚úÖ MPS test successful!\n",
            "Test tensor shape: torch.Size([3, 3])\n",
            "Result tensor shape: torch.Size([3, 3])\n",
            "=================================================================\n",
            "Layer (type:depth-idx)                   Param #\n",
            "=================================================================\n",
            "‚îú‚îÄConv2d: 1-1                            320\n",
            "‚îú‚îÄConv2d: 1-2                            18,496\n",
            "‚îú‚îÄMaxPool2d: 1-3                         --\n",
            "‚îú‚îÄConv2d: 1-4                            73,856\n",
            "‚îú‚îÄConv2d: 1-5                            295,168\n",
            "‚îú‚îÄMaxPool2d: 1-6                         --\n",
            "‚îú‚îÄConv2d: 1-7                            1,180,160\n",
            "‚îú‚îÄConv2d: 1-8                            4,719,616\n",
            "‚îú‚îÄConv2d: 1-9                            92,170\n",
            "=================================================================\n",
            "Total params: 6,379,786\n",
            "Trainable params: 6,379,786\n",
            "Non-trainable params: 0\n",
            "=================================================================\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "‚îú‚îÄConv2d: 1-1                            320\n",
              "‚îú‚îÄConv2d: 1-2                            18,496\n",
              "‚îú‚îÄMaxPool2d: 1-3                         --\n",
              "‚îú‚îÄConv2d: 1-4                            73,856\n",
              "‚îú‚îÄConv2d: 1-5                            295,168\n",
              "‚îú‚îÄMaxPool2d: 1-6                         --\n",
              "‚îú‚îÄConv2d: 1-7                            1,180,160\n",
              "‚îú‚îÄConv2d: 1-8                            4,719,616\n",
              "‚îú‚îÄConv2d: 1-9                            92,170\n",
              "=================================================================\n",
              "Total params: 6,379,786\n",
              "Trainable params: 6,379,786\n",
              "Non-trainable params: 0\n",
              "================================================================="
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "# use_cuda = torch.cuda.is_available()\n",
        "# device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "# Check for MPS (Metal Performance Shaders) availability on Apple Silicon\n",
        "mps_available = torch.backends.mps.is_available()\n",
        "print(f\"MPS Available: {mps_available}\")\n",
        "\n",
        "# Check if MPS is built\n",
        "mps_built = torch.backends.mps.is_built()\n",
        "print(f\"MPS Built: {mps_built}\")\n",
        "\n",
        "# Set device based on availability\n",
        "if mps_available and mps_built:\n",
        "    device = torch.device(\"mps\")\n",
        "    print(\"Using MPS (Apple Silicon GPU)\")\n",
        "elif torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"Using CUDA (NVIDIA GPU)\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Using CPU\")\n",
        "\n",
        "print(f\"Selected device: {device}\")\n",
        "\n",
        "# Test MPS with a simple tensor operation\n",
        "if device.type == \"mps\":\n",
        "    try:\n",
        "        # Create a simple tensor on MPS\n",
        "        test_tensor = torch.randn(3, 3, device=device)\n",
        "        result = test_tensor @ test_tensor.T\n",
        "        print(\"‚úÖ MPS test successful!\")\n",
        "        print(f\"Test tensor shape: {test_tensor.shape}\")\n",
        "        print(f\"Result tensor shape: {result.shape}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå MPS test failed: {e}\")\n",
        "        print(\"Falling back to CPU\")\n",
        "        device = torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data to plot accuracy and loss graphs\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "\n",
        "test_incorrect_pred = {'images': [], 'ground_truths': [], 'predicted_vals': []}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqTWLaM5GHgH",
        "outputId": "c91d9ddc-b66b-45f5-eca3-32a5679dd3b9"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(1)\n",
        "batch_size = 128\n",
        "num_epochs = 3\n",
        "scheduler = None\n",
        "learning_rate = 0.001\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if mps_available else {}\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8fDefDhaFlwH"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def GetCorrectPredCount(pPrediction, pLabels):\n",
        "  return pPrediction.argmax(dim=1).eq(pLabels).sum().item()\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    processed = 0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        correct += GetCorrectPredCount(output, target)\n",
        "        processed += len(data)\n",
        "        pbar.set_description(desc= f'Train: Loss={loss.item():0.4f} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
        "        \n",
        "    train_acc.append(100*correct/processed)\n",
        "    train_losses.append(train_loss/len(train_loader))\n",
        "    report_gen.log_model_info(model)\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_acc.append(100. * correct / len(test_loader.dataset))\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMWbLWO6FuHb",
        "outputId": "1e9b0ff2-c02f-4bf4-e2da-341a2fa872f1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/469 [00:00<?, ?it/s]/Users/pankajkumar/Documents/git/TSAI/ERA4/S5/mnist-training-epon/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/var/folders/8x/pf7m6cb161jf51bn3f7q8c980000gn/T/ipykernel_31313/3267201574.py:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n",
            "Train: Loss=2.1523 Batch_id=468 Accuracy=17.48: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 469/469 [00:10<00:00, 45.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 2.1730, Accuracy: 1899/10000 (19%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: Loss=1.9818 Batch_id=468 Accuracy=26.22: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 469/469 [00:10<00:00, 45.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 1.9250, Accuracy: 2766/10000 (28%)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: Loss=1.7093 Batch_id=468 Accuracy=30.12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 469/469 [00:10<00:00, 45.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 1.7672, Accuracy: 3704/10000 (37%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "report_gen.log_experiment_info(\n",
        "    model_name=\"CNN Model\",\n",
        "    dataset=\"MNIST\",\n",
        "    batch_size=batch_size,\n",
        "    epochs=num_epochs,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler\n",
        "    )\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)\n",
        "    report_gen.log_epoch_results(epoch, train_losses, train_acc, test_losses, test_acc, learning_rate)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (My Virtual Env)",
      "language": "python",
      "name": "mnist-training-epon"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
