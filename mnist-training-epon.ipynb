{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "0m2JWFliFfKT"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import base64\n",
        "from io import BytesIO\n",
        "from tabnanny import verbose\n",
        "\n",
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TrainingReportGenerator:\n",
        "    def __init__(self, reports_dir=\"reports\"):\n",
        "        self.reports_dir = reports_dir\n",
        "        self._ensure_reports_directory()\n",
        "        self.report_data = {\n",
        "            'experiment_info': {},\n",
        "            'model_info': {},\n",
        "            'training_history': [],\n",
        "            'test_results': {},\n",
        "            'plots': [],\n",
        "            'metadata': {}\n",
        "        }\n",
        "    \n",
        "    def _ensure_reports_directory(self):\n",
        "        \"\"\"Create reports directory if it doesn't exist\"\"\"\n",
        "        if not os.path.exists(self.reports_dir):\n",
        "            os.makedirs(self.reports_dir)\n",
        "            print(f\"Created reports directory: {self.reports_dir}\")\n",
        "    \n",
        "    def log_experiment_info(self, model_name, dataset, batch_size, epochs, optimizer, scheduler=None):\n",
        "        \"\"\"Log basic experiment information\"\"\"\n",
        "        self.report_data['experiment_info'] = {\n",
        "            'model_name': model_name,\n",
        "            'dataset': dataset,\n",
        "            'batch_size': batch_size,\n",
        "            'epochs': epochs,\n",
        "            'optimizer': str(optimizer),\n",
        "            'scheduler': str(scheduler) if scheduler else None,\n",
        "            'timestamp': datetime.now().isoformat(),\n",
        "            'device': str(device) if 'device' in globals() else 'unknown'\n",
        "        }\n",
        "    \n",
        "    def log_model_info(self, model):\n",
        "        \"\"\"Log model architecture information\"\"\"\n",
        "        total_params = sum(p.numel() for p in model.parameters())\n",
        "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "        \n",
        "        self.report_data['model_info'] = {\n",
        "            'total_parameters': total_params,\n",
        "            'trainable_parameters': trainable_params,\n",
        "            'model_architecture': str(model)\n",
        "        }\n",
        "    \n",
        "    def log_epoch_results(self, epoch, train_loss, train_acc, test_loss, test_acc, lr=None):\n",
        "        \"\"\"Log results for each epoch - handles both single values and lists\"\"\"\n",
        "        # Helper function to extract single value from list or return the value\n",
        "        def extract_value(value):\n",
        "            if isinstance(value, list):\n",
        "                return value[-1] if value else 0\n",
        "            return value\n",
        "        \n",
        "        epoch_data = {\n",
        "            'epoch': epoch,\n",
        "            'train_loss': extract_value(train_loss),\n",
        "            'train_accuracy': extract_value(train_acc),\n",
        "            'test_loss': extract_value(test_loss),\n",
        "            'test_accuracy': extract_value(test_acc),\n",
        "            'learning_rate': lr\n",
        "        }\n",
        "        self.report_data['training_history'].append(epoch_data)\n",
        "    \n",
        "    def log_final_test_results(self, final_test_loss, final_test_acc, incorrect_predictions=None):\n",
        "        \"\"\"Log final test results - handles both single values and lists\"\"\"\n",
        "        # Handle case where final_test_acc is a list (take the last value)\n",
        "        if isinstance(final_test_acc, list):\n",
        "            final_test_acc_value = final_test_acc[-1] if final_test_acc else 0\n",
        "        else:\n",
        "            final_test_acc_value = final_test_acc\n",
        "        \n",
        "        # Handle case where final_test_loss is a list (take the last value)\n",
        "        if isinstance(final_test_loss, list):\n",
        "            final_test_loss_value = final_test_loss[-1] if final_test_loss else 0\n",
        "        else:\n",
        "            final_test_loss_value = final_test_loss\n",
        "        \n",
        "        self.report_data['test_results'] = {\n",
        "            'final_test_loss': float(final_test_loss_value),\n",
        "            'final_test_accuracy': float(final_test_acc_value),\n",
        "            'incorrect_predictions_count': len(incorrect_predictions) if incorrect_predictions else 0\n",
        "        }\n",
        "    \n",
        "    def add_plot(self, plot_type, title, description=\"\"):\n",
        "        \"\"\"Add a plot to the report\"\"\"\n",
        "        # Capture current matplotlib figure\n",
        "        fig = plt.gcf()\n",
        "        buffer = BytesIO()\n",
        "        fig.savefig(buffer, format='png', dpi=150, bbox_inches='tight')\n",
        "        buffer.seek(0)\n",
        "        plot_data = base64.b64encode(buffer.getvalue()).decode()\n",
        "        plt.close(fig)\n",
        "        \n",
        "        self.report_data['plots'].append({\n",
        "            'type': plot_type,\n",
        "            'title': title,\n",
        "            'description': description,\n",
        "            'data': plot_data\n",
        "        })\n",
        "    \n",
        "    def generate_html_report(self, filename=None, custom_name=None):\n",
        "        \"\"\"Generate HTML report in the reports directory\"\"\"\n",
        "        if filename is None:\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            model_name = self.report_data['experiment_info'].get('model_name', 'model')\n",
        "            dataset = self.report_data['experiment_info'].get('dataset', 'dataset')\n",
        "            \n",
        "            if custom_name:\n",
        "                filename = f\"{custom_name}_{timestamp}.html\"\n",
        "            else:\n",
        "                filename = f\"{model_name}_{dataset}_{timestamp}.html\"\n",
        "        \n",
        "        # Ensure filename has .html extension\n",
        "        if not filename.endswith('.html'):\n",
        "            filename += '.html'\n",
        "        \n",
        "        # Create full path in reports directory\n",
        "        filepath = os.path.join(self.reports_dir, filename)\n",
        "        \n",
        "        html_content = self._create_html_template()\n",
        "        \n",
        "        with open(filepath, 'w') as f:\n",
        "            f.write(html_content)\n",
        "        \n",
        "        print(f\"HTML report generated: {filepath}\")\n",
        "        return filepath\n",
        "    \n",
        "    def _create_html_template(self):\n",
        "        \"\"\"Create HTML template with embedded data\"\"\"\n",
        "        exp_info = self.report_data['experiment_info']\n",
        "        model_info = self.report_data['model_info']\n",
        "        training_history = self.report_data['training_history']\n",
        "        test_results = self.report_data['test_results']\n",
        "        plots = self.report_data['plots']\n",
        "        \n",
        "        # Safe formatting with fallbacks\n",
        "        final_acc = test_results.get('final_test_accuracy', 0)\n",
        "        final_loss = test_results.get('final_test_loss', 0)\n",
        "        total_epochs = len(training_history)\n",
        "        total_params = model_info.get('total_parameters', 0)\n",
        "        \n",
        "        html = f\"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>Training Report - {exp_info.get('model_name', 'Unknown Model')}</title>\n",
        "    <style>\n",
        "        body {{ font-family: Arial, sans-serif; margin: 40px; background-color: #f5f5f5; }}\n",
        "        .container {{ max-width: 1200px; margin: 0 auto; background-color: white; padding: 30px; border-radius: 10px; box-shadow: 0 0 20px rgba(0,0,0,0.1); }}\n",
        "        h1 {{ color: #2c3e50; border-bottom: 3px solid #3498db; padding-bottom: 10px; }}\n",
        "        h2 {{ color: #34495e; margin-top: 30px; }}\n",
        "        .info-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; margin: 20px 0; }}\n",
        "        .info-card {{ background-color: #ecf0f1; padding: 20px; border-radius: 8px; border-left: 4px solid #3498db; }}\n",
        "        .metric {{ display: flex; justify-content: space-between; margin: 10px 0; padding: 8px; background-color: #fff; border-radius: 4px; }}\n",
        "        .metric-value {{ font-weight: bold; color: #27ae60; }}\n",
        "        table {{ width: 100%; border-collapse: collapse; margin: 20px 0; }}\n",
        "        th, td {{ padding: 12px; text-align: left; border-bottom: 1px solid #ddd; }}\n",
        "        th {{ background-color: #3498db; color: white; }}\n",
        "        tr:nth-child(even) {{ background-color: #f2f2f2; }}\n",
        "        .plot-container {{ text-align: center; margin: 30px 0; }}\n",
        "        .plot-container img {{ max-width: 100%; height: auto; border: 1px solid #ddd; border-radius: 8px; }}\n",
        "        .summary-stats {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px; margin: 20px 0; }}\n",
        "        .stat-card {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 10px; text-align: center; }}\n",
        "        .stat-value {{ font-size: 2em; font-weight: bold; margin: 10px 0; }}\n",
        "        .timestamp {{ color: #7f8c8d; font-size: 0.9em; }}\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <div class=\"container\">\n",
        "        <h1>üß† Training Report</h1>\n",
        "        <p class=\"timestamp\">Generated on: {exp_info.get('timestamp', 'Unknown')}</p>\n",
        "        \n",
        "        <h2> Experiment Summary</h2>\n",
        "        <div class=\"summary-stats\">\n",
        "            <div class=\"stat-card\">\n",
        "                <div>Final Accuracy</div>\n",
        "                <div class=\"stat-value\">{final_acc:.2f}%</div>\n",
        "            </div>\n",
        "            <div class=\"stat-card\">\n",
        "                <div>Final Loss</div>\n",
        "                <div class=\"stat-value\">{final_loss:.4f}</div>\n",
        "            </div>\n",
        "            <div class=\"stat-card\">\n",
        "                <div>Total Epochs</div>\n",
        "                <div class=\"stat-value\">{total_epochs}</div>\n",
        "            </div>\n",
        "            <div class=\"stat-card\">\n",
        "                <div>Model Parameters</div>\n",
        "                <div class=\"stat-value\">{total_params:,}</div>\n",
        "            </div>\n",
        "        </div>\n",
        "        \n",
        "        <h2>üîß Experiment Configuration</h2>\n",
        "        <div class=\"info-grid\">\n",
        "            <div class=\"info-card\">\n",
        "                <h3>Model & Dataset</h3>\n",
        "                <div class=\"metric\"><span>Model:</span><span class=\"metric-value\">{exp_info.get('model_name', 'Unknown')}</span></div>\n",
        "                <div class=\"metric\"><span>Dataset:</span><span class=\"metric-value\">{exp_info.get('dataset', 'Unknown')}</span></div>\n",
        "                <div class=\"metric\"><span>Device:</span><span class=\"metric-value\">{exp_info.get('device', 'Unknown')}</span></div>\n",
        "            </div>\n",
        "            <div class=\"info-card\">\n",
        "                <h3>Training Parameters</h3>\n",
        "                <div class=\"metric\"><span>Batch Size:</span><span class=\"metric-value\">{exp_info.get('batch_size', 'Unknown')}</span></div>\n",
        "                <div class=\"metric\"><span>Epochs:</span><span class=\"metric-value\">{exp_info.get('epochs', 'Unknown')}</span></div>\n",
        "                <div class=\"metric\"><span>Trainable Params:</span><span class=\"metric-value\">{model_info.get('trainable_parameters', 0):,}</span></div>\n",
        "            </div>\n",
        "        </div>\n",
        "        \n",
        "        <h2>üìà Training History</h2>\n",
        "        <table>\n",
        "            <thead>\n",
        "                <tr>\n",
        "                    <th>Epoch</th>\n",
        "                    <th>Train Loss</th>\n",
        "                    <th>Train Acc (%)</th>\n",
        "                    <th>Test Loss</th>\n",
        "                    <th>Test Acc (%)</th>\n",
        "                    <th>Learning Rate</th>\n",
        "                </tr>\n",
        "            </thead>\n",
        "            <tbody>\n",
        "\"\"\"\n",
        "        \n",
        "        # Add training history rows with safe formatting\n",
        "        for epoch_data in training_history:\n",
        "            train_loss = epoch_data.get('train_loss', 0)\n",
        "            train_acc = epoch_data.get('train_accuracy', 0)\n",
        "            test_loss = epoch_data.get('test_loss', 0)\n",
        "            test_acc = epoch_data.get('test_accuracy', 0)\n",
        "            lr = epoch_data.get('learning_rate', 'N/A')\n",
        "            \n",
        "            # Safe formatting function\n",
        "            def safe_format(value, format_str):\n",
        "                try:\n",
        "                    if isinstance(value, (int, float)):\n",
        "                        return format_str.format(value)\n",
        "                    else:\n",
        "                        return str(value)\n",
        "                except:\n",
        "                    return str(value)\n",
        "            \n",
        "            html += f\"\"\"\n",
        "                <tr>\n",
        "                    <td>{epoch_data.get('epoch', 'N/A')}</td>\n",
        "                    <td>{safe_format(train_loss, '{:.4f}')}</td>\n",
        "                    <td>{safe_format(train_acc, '{:.2f}')}</td>\n",
        "                    <td>{safe_format(test_loss, '{:.4f}')}</td>\n",
        "                    <td>{safe_format(test_acc, '{:.2f}')}</td>\n",
        "                    <td>{lr}</td>\n",
        "                </tr>\n",
        "\"\"\"\n",
        "        \n",
        "        html += \"\"\"\n",
        "            </tbody>\n",
        "        </table>\n",
        "        \n",
        "        <h2> Training Plots</h2>\n",
        "\"\"\"\n",
        "        \n",
        "        # Add plots\n",
        "        for plot in plots:\n",
        "            html += f\"\"\"\n",
        "        <div class=\"plot-container\">\n",
        "            <h3>{plot.get('title', 'Plot')}</h3>\n",
        "            <p>{plot.get('description', '')}</p>\n",
        "            <img src=\"data:image/png;base64,{plot.get('data', '')}\" alt=\"{plot.get('title', 'Plot')}\">\n",
        "        </div>\n",
        "\"\"\"\n",
        "        \n",
        "        html += \"\"\"\n",
        "    </div>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "        return html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "report_gen = TrainingReportGenerator(reports_dir=\"reports\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdydjYTZFyi3",
        "outputId": "b6c9bcac-6a1f-4657-d03c-dab9ea58b696"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /Users/pankajkumar/miniconda3/lib/python3.12/site-packages (1.5.1)\n",
            "MPS Available: True\n",
            "MPS Built: True\n",
            "Using MPS (Apple Silicon GPU)\n",
            "Selected device: mps\n",
            "‚úÖ MPS test successful!\n",
            "Test tensor shape: torch.Size([3, 3])\n",
            "Result tensor shape: torch.Size([3, 3])\n"
          ]
        }
      ],
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "# use_cuda = torch.cuda.is_available()\n",
        "# device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "# Check for MPS (Metal Performance Shaders) availability on Apple Silicon\n",
        "mps_available = torch.backends.mps.is_available()\n",
        "print(f\"MPS Available: {mps_available}\")\n",
        "\n",
        "# Check if MPS is built\n",
        "mps_built = torch.backends.mps.is_built()\n",
        "print(f\"MPS Built: {mps_built}\")\n",
        "\n",
        "# Set device based on availability\n",
        "if mps_available and mps_built:\n",
        "    device = torch.device(\"mps\")\n",
        "    print(\"Using MPS (Apple Silicon GPU)\")\n",
        "elif torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"Using CUDA (NVIDIA GPU)\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Using CPU\")\n",
        "\n",
        "print(f\"Selected device: {device}\")\n",
        "\n",
        "# Test MPS with a simple tensor operation\n",
        "if device.type == \"mps\":\n",
        "    try:\n",
        "        # Create a simple tensor on MPS\n",
        "        test_tensor = torch.randn(3, 3, device=device)\n",
        "        result = test_tensor @ test_tensor.T\n",
        "        print(\"‚úÖ MPS test successful!\")\n",
        "        print(f\"Test tensor shape: {test_tensor.shape}\")\n",
        "        print(f\"Result tensor shape: {result.shape}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå MPS test failed: {e}\")\n",
        "        print(\"Falling back to CPU\")\n",
        "        device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 8, 3, padding=1) # input - 1*28*28 Output - 4*28*28  RF - 3*3\n",
        "        self.bn1 = nn.BatchNorm2d(8)\n",
        "        self.conv2 = nn.Conv2d(8, 16, 3, padding=1) # input - 4*28*28 Output - 8*28*28  RF - 5*5\n",
        "        self.bn2 = nn.BatchNorm2d(16)\n",
        "        self.drop1 = nn.Dropout2d(0.05)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2) # input - 8*28*28 Output - 8*14*14  RF - 5*5\n",
        "        self.conv3 = nn.Conv2d(16, 32, 3, padding=1) # input - 8*14*14 Output - 16*14*14  RF - 9*9\n",
        "        self.bn3 = nn.BatchNorm2d(32)\n",
        "        self.conv4 = nn.Conv2d(32, 24, 3, padding=1) # input - 16*14*14 Output - 32*14*14  RF - 13*13\n",
        "        self.bn4 = nn.BatchNorm2d(24)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2) # input - 32*14*14 Output - 32*7*7  RF - 13*13\n",
        "        self.conv5 = nn.Conv2d(24, 16, 3) # input - 32*7*7 Output - 16*5*5  RF - 21*21\n",
        "        self.bn5 = nn.BatchNorm2d(16)\n",
        "        self.conv6 = nn.Conv2d(16, 12, 3) # input - 16*5*5 Output - 12*3*3  RF - 29*29\n",
        "        self.bn6 = nn.BatchNorm2d(12)\n",
        "        self.conv7 = nn.Conv2d(12, 10, 3) # input - 12*3*3 Output - 10*1*1  RF - 37*37\n",
        "        self.bn7 = nn.BatchNorm2d(10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x)))))\n",
        "        x = self.pool1(self.drop1(F.relu(self.bn2(self.conv2(F.relu(self.bn1(self.conv1(x))))))))\n",
        "        x = self.pool2(F.relu(self.bn4(self.conv4(F.relu(self.bn3(self.conv3(x)))))))\n",
        "        x = F.relu(self.bn6(self.conv6(F.relu(self.bn5(self.conv5(x))))))\n",
        "        x = F.relu(self.bn7(self.conv7(x)))\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (drop1): Dropout2d(p=0.05, inplace=False)\n",
              "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv4): Conv2d(32, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv5): Conv2d(24, 16, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (bn5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv6): Conv2d(16, 12, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (bn6): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv7): Conv2d(12, 10, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (bn7): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Net()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data to plot accuracy and loss graphs\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "\n",
        "test_incorrect_pred = {'images': [], 'ground_truths': [], 'predicted_vals': []}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqTWLaM5GHgH",
        "outputId": "c91d9ddc-b66b-45f5-eca3-32a5679dd3b9"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(1)\n",
        "batch_size = 32\n",
        "num_epochs = 20\n",
        "scheduler = None\n",
        "learning_rate = 0.001\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((28, 28)),\n",
        "    # transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.RandomRotation(degrees=20),\n",
        "    # transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.5, 1.5), shear=10, resample=False, fillcolor=0),\n",
        "    # transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "    # transforms.RandomHorizontalFlip(p=0.2),\n",
        "    # transforms.RandomVerticalFlip(p=0.2),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(), \n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=train_transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=test_transform)\n",
        "\n",
        "kwargs = {'num_workers': 0, 'pin_memory': True} if mps_available else {}\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True, \n",
        "    **kwargs\n",
        "    )\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset=test_dataset, \n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([60000, 28, 28]), torch.Size([10000, 28, 28]))"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_loader.dataset.data.shape, test_loader.dataset.data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "8fDefDhaFlwH"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def GetCorrectPredCount(pPrediction, pLabels):\n",
        "  return pPrediction.argmax(dim=1).eq(pLabels).sum().item()\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    processed = 0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        correct += GetCorrectPredCount(output, target)\n",
        "        processed += len(data)\n",
        "        pbar.set_description(desc= f'Train: Loss={loss.item():0.4f} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}% ')\n",
        "        \n",
        "    train_acc.append(100*correct/processed)\n",
        "    train_losses.append(train_loss/len(train_loader))\n",
        "    report_gen.log_model_info(model)\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_acc.append(100. * correct / len(test_loader.dataset))\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=================================================================\n",
            "Layer (type:depth-idx)                   Param #\n",
            "=================================================================\n",
            "‚îú‚îÄConv2d: 1-1                            80\n",
            "‚îú‚îÄBatchNorm2d: 1-2                       16\n",
            "‚îú‚îÄConv2d: 1-3                            1,168\n",
            "‚îú‚îÄBatchNorm2d: 1-4                       32\n",
            "‚îú‚îÄDropout2d: 1-5                         --\n",
            "‚îú‚îÄMaxPool2d: 1-6                         --\n",
            "‚îú‚îÄConv2d: 1-7                            4,640\n",
            "‚îú‚îÄBatchNorm2d: 1-8                       64\n",
            "‚îú‚îÄConv2d: 1-9                            6,936\n",
            "‚îú‚îÄBatchNorm2d: 1-10                      48\n",
            "‚îú‚îÄMaxPool2d: 1-11                        --\n",
            "‚îú‚îÄConv2d: 1-12                           3,472\n",
            "‚îú‚îÄBatchNorm2d: 1-13                      32\n",
            "‚îú‚îÄConv2d: 1-14                           1,740\n",
            "‚îú‚îÄBatchNorm2d: 1-15                      24\n",
            "‚îú‚îÄConv2d: 1-16                           1,090\n",
            "‚îú‚îÄBatchNorm2d: 1-17                      20\n",
            "=================================================================\n",
            "Total params: 19,362\n",
            "Trainable params: 19,362\n",
            "Non-trainable params: 0\n",
            "=================================================================\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "‚îú‚îÄConv2d: 1-1                            80\n",
              "‚îú‚îÄBatchNorm2d: 1-2                       16\n",
              "‚îú‚îÄConv2d: 1-3                            1,168\n",
              "‚îú‚îÄBatchNorm2d: 1-4                       32\n",
              "‚îú‚îÄDropout2d: 1-5                         --\n",
              "‚îú‚îÄMaxPool2d: 1-6                         --\n",
              "‚îú‚îÄConv2d: 1-7                            4,640\n",
              "‚îú‚îÄBatchNorm2d: 1-8                       64\n",
              "‚îú‚îÄConv2d: 1-9                            6,936\n",
              "‚îú‚îÄBatchNorm2d: 1-10                      48\n",
              "‚îú‚îÄMaxPool2d: 1-11                        --\n",
              "‚îú‚îÄConv2d: 1-12                           3,472\n",
              "‚îú‚îÄBatchNorm2d: 1-13                      32\n",
              "‚îú‚îÄConv2d: 1-14                           1,740\n",
              "‚îú‚îÄBatchNorm2d: 1-15                      24\n",
              "‚îú‚îÄConv2d: 1-16                           1,090\n",
              "‚îú‚îÄBatchNorm2d: 1-17                      20\n",
              "=================================================================\n",
              "Total params: 19,362\n",
              "Trainable params: 19,362\n",
              "Non-trainable params: 0\n",
              "================================================================="
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = Net().to(device)\n",
        "summary(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMWbLWO6FuHb",
        "outputId": "1e9b0ff2-c02f-4bf4-e2da-341a2fa872f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 of 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1875 [00:00<?, ?it/s]/Users/pankajkumar/Documents/git/TSAI/ERA4/S5/mnist-training-epon/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/var/folders/8x/pf7m6cb161jf51bn3f7q8c980000gn/T/ipykernel_48206/744218209.py:29: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n",
            "Train: Loss=0.4261 Batch_id=1874 Accuracy=90.86% : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1875/1875 [00:18<00:00, 101.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.1312, Accuracy: 9811/10000 (98.11%)\n",
            "\n",
            "Epoch 2 of 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: Loss=0.1471 Batch_id=1874 Accuracy=95.55% : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1875/1875 [00:18<00:00, 103.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0783, Accuracy: 9870/10000 (98.70%)\n",
            "\n",
            "Epoch 3 of 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: Loss=0.1526 Batch_id=1874 Accuracy=96.27% : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1875/1875 [00:18<00:00, 102.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0520, Accuracy: 9899/10000 (98.99%)\n",
            "\n",
            "Epoch 4 of 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: Loss=0.0940 Batch_id=1874 Accuracy=96.83% : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1875/1875 [00:17<00:00, 105.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0460, Accuracy: 9905/10000 (99.05%)\n",
            "\n",
            "Epoch 5 of 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: Loss=0.0783 Batch_id=1874 Accuracy=97.18% : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1875/1875 [00:18<00:00, 103.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0429, Accuracy: 9904/10000 (99.04%)\n",
            "\n",
            "Epoch 6 of 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: Loss=0.2869 Batch_id=1874 Accuracy=97.40% : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1875/1875 [00:18<00:00, 103.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0350, Accuracy: 9915/10000 (99.15%)\n",
            "\n",
            "Epoch 7 of 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: Loss=0.1681 Batch_id=1874 Accuracy=97.58% : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1875/1875 [00:17<00:00, 105.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0335, Accuracy: 9925/10000 (99.25%)\n",
            "\n",
            "Epoch 8 of 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: Loss=0.0533 Batch_id=1874 Accuracy=97.81% : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1875/1875 [00:17<00:00, 104.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0317, Accuracy: 9927/10000 (99.27%)\n",
            "\n",
            "Epoch 9 of 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: Loss=0.0358 Batch_id=1874 Accuracy=97.98% : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1875/1875 [00:18<00:00, 103.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0293, Accuracy: 9930/10000 (99.30%)\n",
            "\n",
            "Epoch 10 of 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: Loss=0.1140 Batch_id=1874 Accuracy=98.02% : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1875/1875 [00:18<00:00, 101.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0298, Accuracy: 9923/10000 (99.23%)\n",
            "\n",
            "Epoch 11 of 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: Loss=0.0814 Batch_id=1874 Accuracy=98.14% : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1875/1875 [00:17<00:00, 104.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0292, Accuracy: 9929/10000 (99.29%)\n",
            "\n",
            "Epoch 12 of 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: Loss=0.1131 Batch_id=1874 Accuracy=98.20% : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1875/1875 [00:18<00:00, 101.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0293, Accuracy: 9928/10000 (99.28%)\n",
            "\n",
            "Epoch 13 of 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: Loss=0.1490 Batch_id=1874 Accuracy=98.30% : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1875/1875 [00:17<00:00, 105.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0257, Accuracy: 9938/10000 (99.38%)\n",
            "\n",
            "Epoch 14 of 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: Loss=0.0212 Batch_id=1874 Accuracy=98.36% : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1875/1875 [00:18<00:00, 101.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0261, Accuracy: 9937/10000 (99.37%)\n",
            "\n",
            "Epoch 15 of 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: Loss=0.2754 Batch_id=1874 Accuracy=98.42% : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1875/1875 [00:18<00:00, 103.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0266, Accuracy: 9940/10000 (99.40%)\n",
            "\n",
            "Epoch 16 of 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: Loss=0.0306 Batch_id=1874 Accuracy=98.42% : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1875/1875 [00:17<00:00, 105.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0250, Accuracy: 9935/10000 (99.35%)\n",
            "\n",
            "Epoch 17 of 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: Loss=0.0284 Batch_id=1874 Accuracy=98.52% : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1875/1875 [00:18<00:00, 103.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0233, Accuracy: 9938/10000 (99.38%)\n",
            "\n",
            "Epoch 18 of 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: Loss=0.0465 Batch_id=1874 Accuracy=98.59% : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1875/1875 [00:18<00:00, 102.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0246, Accuracy: 9933/10000 (99.33%)\n",
            "\n",
            "Epoch 19 of 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: Loss=0.0335 Batch_id=1874 Accuracy=98.59% : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1875/1875 [00:18<00:00, 103.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0225, Accuracy: 9943/10000 (99.43%)\n",
            "\n",
            "Epoch 20 of 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train: Loss=0.1035 Batch_id=1874 Accuracy=98.63% : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1875/1875 [00:17<00:00, 104.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0210, Accuracy: 9947/10000 (99.47%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "report_gen.log_experiment_info(\n",
        "    model_name=\"CNN Model\",\n",
        "    dataset=\"MNIST\",\n",
        "    batch_size=batch_size,\n",
        "    epochs=num_epochs,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler\n",
        "    )\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1} of {num_epochs}\")\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)\n",
        "    report_gen.log_epoch_results(epoch, train_losses, train_acc, test_losses, test_acc, learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(2,2,figsize=(15,10))\n",
        "axs[0, 0].plot(train_losses)\n",
        "axs[0, 0].set_title(\"Training Loss\")\n",
        "axs[1, 0].plot(train_acc)\n",
        "axs[1, 0].set_title(\"Training Accuracy\")\n",
        "axs[0, 1].plot(test_losses)\n",
        "axs[0, 1].set_title(\"Test Loss\")\n",
        "axs[1, 1].plot(test_acc)\n",
        "axs[1, 1].set_title(\"Test Accuracy\")\n",
        "\n",
        "report_gen.add_plot(\"training_curves\", \"Training and Test Curves\", \"Loss and accuracy over epochs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HTML report generated: reports/CNN Model_MNIST_20251003_204943.html\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'reports/CNN Model_MNIST_20251003_204943.html'"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Generate final report\n",
        "report_gen.log_final_test_results(test_losses, test_acc, test_incorrect_pred)\n",
        "report_gen.generate_html_report()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (My Virtual Env)",
      "language": "python",
      "name": "mnist-training-epon"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
